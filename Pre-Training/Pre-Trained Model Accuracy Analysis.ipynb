{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44fe329-5e57-4ad6-ac9f-bdfa0ed06d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_log_name = \"bert_model_accuracy_log.txt\"\n",
    "bert_model_path = \"..\\\\custom_models\\\\bert_model\"\n",
    "tokenized_bookcorpus_dataset_path = '..\\\\custom_datasets\\\\tokenized_bookcorpus_lines_dataset'\n",
    "tokenized_wikipedia_dataset_path = '..\\\\custom_datasets\\\\tokenized_wikipedia_lines_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6cd6e5a-2021-4216-8fae-723a97c47907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.realpath(\"../../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91965361-c4cc-4311-a8ac-7a3b6be062b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import gc\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, BertForPreTraining, DefaultDataCollator\n",
    "from tqdm.auto import tqdm\n",
    "from TokenizedBERTDatasetModule import TokenizedBERTDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98795f3d-60f4-482a-8d4a-54fc1ae23f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83ce2fea7eb41d7a889270e5f631862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d076e2620b64bf28e0c5a6cdb6e15de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_bookcorpus_dataset = load_from_disk(tokenized_bookcorpus_dataset_path)\n",
    "tokenized_wikipedia_dataset = load_from_disk(tokenized_wikipedia_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbcac71c-2e81-441a-93a5-76d09e50164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    TokenizedBERTDataset([tokenized_bookcorpus_dataset['validation'], tokenized_wikipedia_dataset['validation']]),\n",
    "    batch_size=batch_size, collate_fn=DefaultDataCollator(), shuffle=True, pin_memory=True, pin_memory_device=\"cuda:0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ebc4410-8f52-4f31-8457-2b0c4b06fc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = BertForPreTraining.from_pretrained(bert_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f1bd351-e4c6-4c97-a721-219a2bb2d138",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForPreTraining(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertPreTrainingHeads(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=28996, bias=True)\n",
       "    )\n",
       "    (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available else torch.device(\"cpu\")\n",
    "bert_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e46d4711-d08d-4962-a4e4-5621b99353d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_batch_mlm_accuracy(batch, model_outputs, mlm_accuracy_metric):\n",
    "    batch_predictions = []\n",
    "    batch_references = []\n",
    "    for entry_index in range(len(batch['attention_mask'])):\n",
    "        try:\n",
    "            final_attention_index = (batch['attention_mask'][entry_index] == 0).nonzero(as_tuple=True)[0][0].item()\n",
    "        except IndexError:\n",
    "            final_attention_index = len(batch['attention_mask'][entry_index])\n",
    "\n",
    "        predictions = torch.argmax(model_outputs.prediction_logits[entry_index], dim=-1)[:final_attention_index]\n",
    "        references = []\n",
    "        for i in range(final_attention_index):\n",
    "            label_entry = batch['labels'][entry_index][i].item()\n",
    "            if(label_entry == -100):\n",
    "                references.append(batch['input_ids'][entry_index][i].item())\n",
    "            else:\n",
    "                references.append(label_entry)\n",
    "\n",
    "        batch_predictions += predictions\n",
    "        batch_references += references\n",
    "    \n",
    "    mlm_accuracy_metric.add_batch(predictions = batch_predictions, references = batch_references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00fe7033-6fd1-4fb1-983c-db8a403ecdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_batch_nsp_accuracy(batch, model_outputs, nsp_accuracy_metric):\n",
    "    predictions = torch.argmax(model_outputs.seq_relationship_logits, dim=-1)\n",
    "    references = batch['next_sentence_label']\n",
    "    nsp_accuracy_metric.add_batch(predictions = predictions, references = references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e1add5b-08b4-49a4-baac-e3e6baf7bbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_model_accuracies(model, early_stop = 0):\n",
    "    current_index = 0\n",
    "    model.eval()\n",
    "    mlm_accuracy_metric = evaluate.load(\"accuracy\")\n",
    "    nsp_accuracy_metric = evaluate.load(\"accuracy\")\n",
    "    progress_bar = tqdm(range(len(data_loader))) if early_stop == 0 else tqdm(range(early_stop))\n",
    "    for batch in data_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        save_batch_mlm_accuracy(batch, outputs, mlm_accuracy_metric)\n",
    "        save_batch_nsp_accuracy(batch, outputs, nsp_accuracy_metric)\n",
    "\n",
    "        #   Descomente as linhas abaixo somente se estiver tendo problemas de consumo de memória ao executar o script, já que elas aumentam o tempo\n",
    "        #de execução\n",
    "        \n",
    "        # gc.collect()\n",
    "        # torch.cuda.empty_cache()\n",
    "        progress_bar.update(1)\n",
    "        current_index += 1\n",
    "        if(early_stop > 0 and current_index >= early_stop):\n",
    "            break\n",
    "    return mlm_accuracy_metric.compute(), nsp_accuracy_metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b178f81-6f7e-4b5d-bd1f-c0a7358fbef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_accuracies_to_log(accuracy_log, mlm_accuracy, nsp_accuracy):\n",
    "    accuracy_log.write(\"Masked Language Model Accuracy: \" + str(mlm_accuracy) + \"\\n\")\n",
    "    accuracy_log.write(\"Next Sentence Prediction Accuracy: \" + str(nsp_accuracy) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8516496-bd82-4e6e-8647-9c55a964f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_log = open(accuracy_log_name, mode=\"a\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97397648-487c-4c99-ac65-915afd18a4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d53852569a4a9ea17997bcd5516fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m evaluation_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     mlm_accuracy, nsp_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_model_accuracies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbert_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     accuracy_log\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEVALUATION \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(evaluation_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m     write_accuracies_to_log(accuracy_log, mlm_accuracy, nsp_accuracy)\n",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m, in \u001b[0;36mcalculate_model_accuracies\u001b[1;34m(model, early_stop)\u001b[0m\n\u001b[0;32m      8\u001b[0m batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m      9\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[1;32m---> 10\u001b[0m \u001b[43msave_batch_mlm_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlm_accuracy_metric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m save_batch_nsp_accuracy(batch, outputs, nsp_accuracy_metric)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# gc.collect()\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# torch.cuda.empty_cache()\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 10\u001b[0m, in \u001b[0;36msave_batch_mlm_accuracy\u001b[1;34m(batch, model_outputs, mlm_accuracy_metric)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entry_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;66;03m#OBS: What the comparisson \"batch['attention_mask'][entry_index] == 0\" does is: get each element of the list in the left and compare it with\u001b[39;00m\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;66;03m#   the 0 on the right, then make a new list with those results. The 'nonzero' function returns a tuple where each element corresponds to a\u001b[39;00m\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;66;03m#   dimension from the input, and each element is a list of the indices of the non-zero elements in that dimension. Check the documentation for\u001b[39;00m\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;66;03m#   more information.\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m         final_attention_index \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mentry_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43mas_tuple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m         final_attention_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m][entry_index])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for evaluation_index in range(10):\n",
    "    mlm_accuracy, nsp_accuracy = calculate_model_accuracies(bert_model, early_stop = 100)\n",
    "    accuracy_log.write(\"EVALUATION \" + str(evaluation_index + 1) + \":\\n\")\n",
    "    write_accuracies_to_log(accuracy_log, mlm_accuracy, nsp_accuracy)\n",
    "accuracy_log.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
