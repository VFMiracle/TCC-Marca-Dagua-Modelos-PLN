{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7255c5-6ef0-4a84-9b75-89414a463d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "register_watermarked_steps_flag = True\n",
    "batch_size = 16\n",
    "marks_per_watermarked_entry = 3\n",
    "watermark_influence_range = 2\n",
    "watermark_probability = 0.15\n",
    "accuracy_log_name = \"watermarked_bert_model_watermark_accuracy_log.txt\"\n",
    "bert_model_path = \"..\\\\custom_models\\\\watermarked_bert_model\"\n",
    "tokenized_bookcorpus_dataset_path = '..\\\\custom_datasets\\\\tokenized_bookcorpus_lines_dataset'\n",
    "tokenized_wikipedia_dataset_path = '..\\\\custom_datasets\\\\tokenized_wikipedia_lines_dataset'\n",
    "watermark = \"###\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01381b5a-a33c-43b0-b479-834dcab10ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.realpath(\"../../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2ae8e9f-b909-4898-8735-1d601b7cb08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import gc\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertForPreTraining, DefaultDataCollator\n",
    "from tqdm.auto import tqdm\n",
    "from WatermarkedTokenizedBERTDatasetModule import WatermarkedTokenizedBERTDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6884752-6fb5-443d-b13b-23213f099ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19bb665627564308a1813c45bf59a9cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d26e351f00446e9b24f7d11f2705ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_bookcorpus_dataset_dict = load_from_disk(tokenized_bookcorpus_dataset_path)\n",
    "tokenized_wikipedia_dataset_dict = load_from_disk(tokenized_wikipedia_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b69d644-9292-4e08-bd5f-b81e97352815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vande\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = WatermarkedTokenizedBERTDataset(\n",
    "    [tokenized_bookcorpus_dataset['validation'], tokenized_wikipedia_dataset['validation']], watermark_pattern=watermark,\n",
    "    watermark_probability=watermark_probability, watermark_influence_range=watermark_influence_range,\n",
    "    marks_per_watermarked_entry=marks_per_watermarked_entry, register_watermarked_steps_flag=register_watermarked_steps_flag\n",
    ")\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, collate_fn=DefaultDataCollator(), shuffle=True, pin_memory=True, pin_memory_device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "067e4220-845c-4898-935d-8f716a2e1791",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = BertForPreTraining.from_pretrained(bert_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e951948-15f4-44a2-971a-bb48d85e6f01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForPreTraining(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertPreTrainingHeads(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=28996, bias=True)\n",
       "    )\n",
       "    (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "bert_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da7a561e-0ca5-4025-875e-e6e52707fd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_batch_mlm_accuracy(batch, model_outputs, accuracy_metrics, dataset):\n",
    "    batch_predictions = {\"complete\": [], \"normal_token\": [], \"watermark\": []}\n",
    "    batch_references = {\"complete\": [], \"normal_token\": [], \"watermark\": []}\n",
    "    \n",
    "    for entry_index in range(len(batch['attention_mask'])):\n",
    "        try:\n",
    "            final_attention_index = (batch['attention_mask'][entry_index] == 0).nonzero(as_tuple = True)[0][0].item()\n",
    "        except IndexError:\n",
    "            final_attention_index = len(batch['attention_mask'][entry_index])\n",
    "\n",
    "        watermark_indexes = [\n",
    "            index for index, value in enumerate(batch['labels'][entry_index][:final_attention_index]) if value == dataset.watermark_label\n",
    "        ]\n",
    "        \n",
    "        predictions = torch.argmax(model_outputs.prediction_logits[entry_index], dim=-1).tolist()[:final_attention_index]\n",
    "        normal_token_predictions = [value for index, value in enumerate(predictions) if not (index in watermark_indexes)]\n",
    "        watermark_predictions = [value for index, value in enumerate(predictions) if index in watermark_indexes]\n",
    "\n",
    "        watermark_references = [dataset.watermark_label for _ in range(len(watermark_indexes))]\n",
    "        normal_token_references = []\n",
    "        references = []\n",
    "        for i in range(final_attention_index):\n",
    "            label_entry = batch['labels'][entry_index][i].item()\n",
    "            if(label_entry == -100):\n",
    "                reference = batch['input_ids'][entry_index][i].item()\n",
    "            else:\n",
    "                reference = label_entry\n",
    "\n",
    "            references.append(reference)\n",
    "            if(label_entry != dataset.watermark_label):\n",
    "                normal_token_references.append(reference)\n",
    "        \n",
    "        batch_predictions['complete'] += predictions\n",
    "        batch_predictions['normal_token'] += normal_token_predictions\n",
    "        batch_predictions['watermark'] += watermark_predictions\n",
    "        batch_references['complete'] += references\n",
    "        batch_references['normal_token'] += normal_token_references\n",
    "        batch_references['watermark'] += watermark_references\n",
    "\n",
    "    accuracy_metrics['complete'].add_batch(predictions = batch_predictions['complete'], references = batch_references['complete'])\n",
    "    accuracy_metrics['normal_token'].add_batch(predictions = batch_predictions['normal_token'], references = batch_references['normal_token'])\n",
    "    accuracy_metrics['watermark'].add_batch(predictions = batch_predictions['watermark'], references = batch_references['watermark'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c0bcf2b-60a1-4196-b5d0-e63a0540e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_batch_nsp_accuracy(batch, model_outputs, accuracy_metrics, dataset):\n",
    "    predictions = torch.argmax(model_outputs.seq_relationship_logits, dim=-1).tolist()\n",
    "    references = batch['next_sentence_label'].tolist()\n",
    "\n",
    "    watermark_predictions = []\n",
    "    watermark_references = []\n",
    "    normal_token_predictions = []\n",
    "    normal_token_references = []\n",
    "    \n",
    "    for entry_index in range(len(batch['next_sentence_label'])):\n",
    "        if(dataset.watermark_label in batch['labels'][entry_index]):\n",
    "            watermark_predictions.append(torch.argmax(model_outputs.seq_relationship_logits[entry_index]).item())\n",
    "            watermark_references.append(batch['next_sentence_label'][entry_index].item())\n",
    "        else:\n",
    "            normal_token_predictions.append(torch.argmax(model_outputs.seq_relationship_logits[entry_index]).item())\n",
    "            normal_token_references.append(batch['next_sentence_label'][entry_index].item())\n",
    "\n",
    "    accuracy_metrics['complete'].add_batch(predictions = predictions, references = references)\n",
    "    accuracy_metrics['normal_token'].add_batch(predictions = normal_token_predictions, references = normal_token_references)\n",
    "    accuracy_metrics['watermark'].add_batch(predictions = watermark_predictions, references = watermark_references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f208d70a-bec7-4bc3-a50c-675618246dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_model_accuracies(model, early_stop=0):\n",
    "    current_index = 0\n",
    "    model.eval()\n",
    "    mlm_accuracy_metrics = {\n",
    "        'complete': evaluate.load('accuracy'),\n",
    "        'normal_token': evaluate.load('accuracy'),\n",
    "        'watermark': evaluate.load('accuracy')\n",
    "    }\n",
    "    nsp_accuracy_metrics = {\n",
    "        'complete': evaluate.load('accuracy'),\n",
    "        'normal_token': evaluate.load('accuracy'),\n",
    "        'watermark': evaluate.load('accuracy')\n",
    "    }\n",
    "    progress_bar = tqdm(range(len(data_loader))) if early_stop == 0 else tqdm(range(early_stop))\n",
    "    for batch in data_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        save_batch_mlm_accuracy(batch, outputs, mlm_accuracy_metrics, dataset)\n",
    "        save_batch_nsp_accuracy(batch, outputs, nsp_accuracy_metrics, dataset)\n",
    "\n",
    "        progress_bar.update(1)\n",
    "        current_index += 1\n",
    "        if(early_stop > 0 and current_index >= early_stop):\n",
    "            break\n",
    "    return {\n",
    "        'complete': mlm_accuracy_metrics['complete'].compute(),\n",
    "        'normal_token': mlm_accuracy_metrics['normal_token'].compute(),\n",
    "        'watermark': mlm_accuracy_metrics['watermark'].compute()\n",
    "    }, {\n",
    "        'complete': nsp_accuracy_metrics['complete'].compute(),\n",
    "        'normal_token': nsp_accuracy_metrics['normal_token'].compute(),\n",
    "        'watermark': nsp_accuracy_metrics['watermark'].compute()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fec4eb5a-6fd7-44fb-9cbe-d1af9bbe84c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_accuracies_to_log(accuracy_log, mlm_accuracies, nsp_accuracies):\n",
    "    accuracy_log.write(\"Masked Language Model Accuracy: \\n\")\n",
    "    accuracy_log.write(\"\\tComplete: \" + str(mlm_accuracies['complete']) + \"\\n\")\n",
    "    accuracy_log.write(\"\\tNormal Token: \" + str(mlm_accuracies['normal_token']) + \"\\n\")\n",
    "    accuracy_log.write(\"\\tWatermark: \" + str(mlm_accuracies['watermark']) + \"\\n\")\n",
    "\n",
    "    accuracy_log.write(\"Next Setence Prediction Accuracy: \\n\")\n",
    "    accuracy_log.write(\"\\tComplete: \" + str(nsp_accuracies['complete']) + \"\\n\")\n",
    "    accuracy_log.write(\"\\tNormal Token: \" + str(nsp_accuracies['normal_token']) + \"\\n\")\n",
    "    accuracy_log.write(\"\\tWatermark: \" + str(nsp_accuracies['watermark']) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18f2353a-4562-4f31-825d-04444ec2014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_log = open(accuracy_log_name, mode=\"a\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84b780b1-815f-4cf8-b123-612324e2a9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\Vande\\.cache\\huggingface\\modules\\evaluate_modules\\metrics\\evaluate-metric--accuracy\\f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14 (last modified on Sat May 25 08:58:11 2024) since it couldn't be found locally at evaluate-metric--accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from C:\\Users\\Vande\\.cache\\huggingface\\modules\\evaluate_modules\\metrics\\evaluate-metric--accuracy\\f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14 (last modified on Sat May 25 08:58:11 2024) since it couldn't be found locally at evaluate-metric--accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from C:\\Users\\Vande\\.cache\\huggingface\\modules\\evaluate_modules\\metrics\\evaluate-metric--accuracy\\f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14 (last modified on Sat May 25 08:58:11 2024) since it couldn't be found locally at evaluate-metric--accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from C:\\Users\\Vande\\.cache\\huggingface\\modules\\evaluate_modules\\metrics\\evaluate-metric--accuracy\\f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14 (last modified on Sat May 25 08:58:11 2024) since it couldn't be found locally at evaluate-metric--accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from C:\\Users\\Vande\\.cache\\huggingface\\modules\\evaluate_modules\\metrics\\evaluate-metric--accuracy\\f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14 (last modified on Sat May 25 08:58:11 2024) since it couldn't be found locally at evaluate-metric--accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from C:\\Users\\Vande\\.cache\\huggingface\\modules\\evaluate_modules\\metrics\\evaluate-metric--accuracy\\f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14 (last modified on Sat May 25 08:58:11 2024) since it couldn't be found locally at evaluate-metric--accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6676b5444c4943b09f9fa341e02e6b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for evaluation_index in range(1):\n",
    "    mlm_accuracies, nsp_accuracies = calculate_model_accuracies(bert_model, early_stop=1)\n",
    "    accuracy_log.write(\"EVALUATION \" + str(evaluation_index + 1) + \"\\n\")\n",
    "    write_accuracies_to_log(accuracy_log, mlm_accuracies, nsp_accuracies)\n",
    "accuracy_log.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
